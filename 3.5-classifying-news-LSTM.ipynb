{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://wikidocs.net/24586"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 기사 분류: 다중 분류 문제\n",
    "\n",
    "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/케라스-창시자에게-배우는-딥러닝/) 책의 3장 5절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다. 이 노트북의 설명은 케라스 버전 2.2.2에 맞추어져 있습니다. 케라스 최신 버전이 릴리스되면 노트북을 다시 테스트하기 때문에 설명과 코드의 결과가 조금 다를 수 있습니다.\n",
    "\n",
    "----\n",
    "\n",
    "이전 섹션에서 완전 연결된 신경망을 사용해 벡터 입력을 어떻게 두 개의 클래스로 분류하는지 보았습니다. 두 개 이상의 클래스가 있을 때는 어떻게 해야 할까요?\n",
    "\n",
    "이 절에서 로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망을 만들어 보겠습니다. 클래스가 많기 때문에 이 문제는 다중 분류의 예입니다. 각 데이터 포인트가 정확히 하나의 범주로 분류되기 때문에 좀 더 정확히 말하면 단일 레이블 다중 분류 문제입니다. 각 데이터 포인트가 여러 개의 범주(가령, 토픽)에 속할 수 있다면 이런 문제는 다중 레이블 다중 분류의 문제가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로이터 데이터셋\n",
    "\n",
    "1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합인 로이터 데이터셋을 사용하겠습니다. 이 데이터셋은 텍스트 분류를 위해 널리 사용되는 간단한 데이터셋입니다. 46개의 토픽이 있으며 어떤 토픽은 다른 것에 비해 데이터가 많습니다. 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있습니다.\n",
    "\n",
    "IMDB와 MNIST와 마찬가지로 로이터 데이터셋은 케라스에 포함되어 있습니다. 한 번 살펴보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB 데이터셋에서처럼 num_words=10000 매개변수는 데이터에서 가장 자주 등장하는 단어 10,000개로 제한합니다.\n",
    "\n",
    "여기에는 8,982개의 훈련 샘플과 2,246개의 테스트 샘플이 있습니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 num_words는 이 데이터에서 등장 빈도 순위로 몇 번째에 해당하는 단어까지만 사용할 것인지 조절합니다. 예를 들어서 100이란 값을 넣으면, 등장 빈도 순위가 1~100에 해당하는 단어만 사용하게 됩니다. 모든 단어를 사용하고자 한다면 None으로 설정합니다. 정확하게 무슨 의미인지 이해가 안간다면, 아래에서 훈련 데이터를 출력할 때 출력되는 정수들을 보면 이해할 수 있습니다.\n",
    "\n",
    "test_split은 전체 뉴스 기사 데이터 중 테스트용 뉴스 기사로 몇 퍼센트를 사용할 것인지를 의미합니다. 이번 실습에서는 전체 뉴스 기사 중 20%를 테스트용 뉴스 기사로 사용할 것이므로, 0.2로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('훈련용 뉴스 기사 : {}'.format(len(train_data)))\n",
    "print('테스트용 뉴스 기사 : {}'.format(len(test_data)))\n",
    "num_classes = max(train_labels) + 1\n",
    "print('카테고리 : {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB 리뷰처럼 각 샘플은 정수 리스트입니다(단어 인덱스):\n",
    "y_train는 0부터 시작하는 숫자들로 카테고리 라벨을 부여하므로, 가장 큰 수에 +1을 하여 출력하면 카테고리가 총 몇 개인지를 알 수 있습니다. 훈련용 뉴스 기사는 8,982개, 테스트용 뉴스 기사는 2,246개, 카테고리는 46개인것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "궁금한 경우를 위해 어떻게 단어로 디코딩하는지 알아보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플에 연결된 레이블은 토픽의 인덱스로 0과 45 사이의 정수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data[0]) # 첫번째 훈련용 뉴스 기사\n",
    "print(train_labels[0]) # 첫번째 훈련용 뉴스 기사의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 훈련용 뉴스 기사 데이터인 X_train 중 첫번째 뉴스 기사인 X_train[0]에는 정수의 나열이 저장되어있습니다. 텍스트가 아니라서 의아할 수 있는데, 현재 이 데이터는 토큰화과 정수 인코딩(각 단어를 정수로 변환)이 끝난 상태입니다.\n",
    "\n",
    "이 데이터는 단어들이 몇 번 등장하는 지의 빈도에 따라서 인덱스를 부여했습니다. 1이라는 숫자는 이 단어가 이 데이터에서 등장 빈도가 1등이라는 뜻입니다. 27,595라는 숫자는 이 단어가 데이터에서 27,595번째로 빈도수가 높은 단어라는 뜻입니다. 즉, 실제로는 빈도가 굉장히 낮은 단어라는 뜻입니다. 앞서 num_words에다가 None을 부여했는데, 만약 num_words에 1,000을 넣었다면 빈도수 순위가 1,000 이하의 단어만 가져온다는 의미이므로 데이터에서 1,000을 넘는 정수는 나오지 않습니다.\n",
    "\n",
    "뉴스 기사들의 레이블들을 의미하는 y_train에서 첫번째 뉴스 기사의 레이블인 y_train[0]에는 3이라는 값이 들어있습니다. 이 숫자는 첫번째 훈련용 뉴스 기사가 46개의 카테고리 중 3에 해당하는 카테고리임을 의미합니다. 방금 확인한 X_train[0]과 y_train[0]은 8,982개의 훈련용 뉴스 기사 중 첫번째 뉴스 기사의 본문과 레이블만 확인한 것입니다. 이번에는 8,982개의 훈련용 뉴스 기사의 길이가 대체적으로 어떤 크기를 가지는지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('뉴스 기사의 최대 길이 :{}'.format(max(len(l) for l in train_data)))\n",
    "print('뉴스 기사의 평균 길이 :{}'.format(sum(map(len, train_data))/len(train_data)))\n",
    "\n",
    "plt.hist([len(s) for s in train_data], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 뉴스의 길이는 다르며, 대체적으로 대부분의 뉴스가 100~200 사이의 길이를 가지는 것을 많은 것을 알 수 있습니다. 이제 각 뉴스가 어떤 종류의 뉴스에 속하는지 기재되어있는 레이블 값의 분포를 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(12,5)\n",
    "sns.countplot(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3, 4가 가장 많은 레이블을 차지하는 것을 확인할 수 있습니다. 각 레이블에 대한 정확한 개수를 알아보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique_elements, counts_elements = np.unique(train_data, return_counts=True)\n",
    "print(\"각 레이블에 대한 빈도수:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "# label_cnt=dict(zip(unique_elements, counts_elements))\n",
    "# 아래의 출력 결과가 보기 불편하여 병렬로 보고싶다면 위의 label_cnt를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3번 레이블은 총 3,159개가 존재하고 4번 레이블은 총 1,949개가 존재하는 것을 확인할 수 있습니다. X_train에 들어있는 숫자들이 각자 어떤 단어들을 나타내고 있는지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_to_index = reuters.get_word_index()\n",
    "#print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "무수히 많은 단어가 등장하기 때문에 출력 결과는 중간에 생략했습니다. 어떤 단어에 어떤 인덱스가 부여되었는지를 알 수는 있는데 이렇게 보는 것은 불편합니다. 좀 더 쉽게 확인하기 위해서 인덱스로부터 단어를 바로 알 수 있도록 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = reuters.get_word_index()\n",
    "print(word_to_index)\n",
    "\n",
    "index_to_word = {}\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 index_to_word[ ]에다가 인덱스를 입력하면 단어를 확인할 수 있습니다. 28,842란 인덱스를 가진 단어는 무엇일까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('빈도수 상위 28842번 단어 : {}'.format(index_to_word[28842]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nondiscriminatory는 잘 쓰이지 않는 단어라서 등장 빈도 순위로 따지면 28,842등이라는 뜻입니다. 1번 단어는 무엇일까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('빈도수 상위 1번 단어 : {}'.format(index_to_word[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빈도수 상위 1번 단어 : the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in train_data[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 index_to_word를 이용해서 첫번째 훈련용 뉴스 기사인 X_train[0]가 어떤 단어들로 구성되어있는지를 복원해보겠습니다. 이는 X_train[0]에 있는 모든 단어들을 하나씩 불러와서 index_to_word의 입력으로 넣고 이를 계속해서 저장하면 됩니다. 아래는 복원된 결과를 보여줍니다. (물론 정수 인코딩을 수행하기 전에도 어느정도 전처리가 된 상태라서 제대로 된 문장이 나오지는 않습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "이전의 예제와 동일한 코드를 사용해서 데이터를 벡터로 변환합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터 벡터 변환\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터 벡터 변환\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블을 벡터로 바꾸는 방법은 두 가지입니다. 레이블의 리스트를 정수 텐서로 변환하는 것과 원-핫 인코딩을 사용하는 것입니다. 원-핫 인코딩이 범주형 데이터에 널리 사용되기 때문에 범주형 인코딩이라고도 부릅니다. 원-핫 인코딩에 대한 자세한 설명은 6.1절을 참고하세요. 이 경우 레이블의 원-핫 인코딩은 각 레이블의 인덱스 자리는 1이고 나머지는 모두 0인 벡터입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 레이블 벡터 변환\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "# 테스트 레이블 벡터 변환\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 예제에서 이미 보았듯이 케라스에는 이를 위한 내장 함수가 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성\n",
    "\n",
    "이 토픽 분류 문제는 이전의 영화 리뷰 분류 문제와 비슷해 보입니다. 두 경우 모두 짧은 텍스트를 분류하는 것이죠. 여기에서는 새로운 제약 사항이 추가되었습니다. 출력 클래스의 개수가 2에서 46개로 늘어난 점입니다. 출력 공간의 차원이 훨씬 커졌습니다.\n",
    "\n",
    "이전에 사용했던 것처럼 `Dense` 층을 쌓으면 각 층은 이전 층의 출력에서 제공한 정보만 사용할 수 있습니다. 한 층이 분류 문제에 필요한 일부 정보를 누락하면 그 다음 층에서 이를 복원할 방법이 없습니다. 각 층은 잠재적으로 정보의 병목이 될 수 있습니다. 이전 예제에서 16차원을 가진 중간층을 사용했지만 16차원 공간은 46개의 클래스를 구분하기에 너무 제약이 많을 것 같습니다. 이렇게 규모가 작은 층은 유용한 정보를 완전히 잃게 되는 정보의 병목 지점처럼 동작할 수 있습니다.\n",
    "\n",
    "이런 이유로 좀 더 규모가 큰 층을 사용하겠습니다. 64개의 유닛을 사용해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 구조에서 주목해야 할 점이 두 가지 있습니다:\n",
    "\n",
    "* 마지막 `Dense` 층의 크기가 46입니다. 각 입력 샘플에 대해서 46차원의 벡터를 출력한다는 뜻입니다. 이 벡터의 각 원소(각 차원)은 각기 다른 출력 클래스가 인코딩된 것입니다.\n",
    "* 마지막 층에 `softmax` 활성화 함수가 사용되었습니다. MNIST 예제에서 이런 방식을 보았습니다. 각 입력 샘플마다 46개의 출력 클래스에 대한 확률 분포를 출력합니다. 즉, 46차원의 출력 벡터를 만들며 `output[i]`는 어떤 샘플이 클래스 `i`에 속할 확률입니다. 46개의 값을 모두 더하면 1이 됩니다.\n",
    "\n",
    "이런 문제에 사용할 최선의 손실 함수는 `categorical_crossentropy`입니다. 이 함수는 두 확률 분포의 사이의 거리를 측정합니다. 여기에서는 네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리입니다. 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 검증\n",
    "\n",
    "훈련 데이터에서 1,000개의 샘플을 따로 떼어서 검증 세트로 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 20번의 에포크로 모델을 훈련시킵니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실과 정확도 곡선을 그려 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # 그래프를 초기화합니다\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 9번째 에포크 이후에 과대적합이 시작됩니다. 9번의 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대략 78%의 정확도를 달성했습니다. 균형 잡힌 이진 분류 문제에서 완전히 무작위로 분류하면 50%의 정확도를 달성합니다. 이 문제는 불균형한 데이터셋을 사용하므로 무작위로 분류하면 19% 정도를 달성합니다. 여기에 비하면 이 결과는 꽤 좋은 편입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 새로운 데이터에 대해 예측하기\n",
    "\n",
    "모델 인스턴스의 `predict` 메서드는 46개 토픽에 대한 확률 분포를 반환합니다. 테스트 데이터 전체에 대한 토픽을 예측해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predictions`의 각 항목은 길이가 46인 벡터입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 벡터의 원소 합은 1입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 큰 값이 예측 클래스가 됩니다. 즉, 가장 확률이 높은 클래스입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 레이블과 손실을 다루는 다른 방법\n",
    "\n",
    "앞서 언급한 것처럼 레이블을 인코딩하는 다른 방법은 다음과 같이 정수 텐서로 변환하는 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 방식을 사용하려면 손실 함수 하나만 바꾸면 됩니다. 코드 3-21에 사용된 손실 함수 `categorical_crossentropy`는 레이블이 범주형 인코딩되어 있을 것이라고 기대합니다. 정수 레이블을 사용할 때는 `sparse_categorical_crossentropy`를 사용해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 손실 함수는 인터페이스만 다를 뿐이고 수학적으로는 `categorical_crossentropy`와 동일합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 충분히 큰 중간층을 두어야 하는 이유\n",
    "\n",
    "앞서 언급한 것처럼 마지막 출력이 46차원이기 때문에 중간층의 히든 유닛이 46개보다 많이 적어서는 안 됩니다. 46차원보다 훨씬 작은 중간층(예를 들면 4차원)을 두면 정보의 병목이 어떻게 나타나는지 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 정확도의 최고 값은 약 71%로 8% 정도 감소되었습니다. 이런 손실의 대부분 원인은 많은 정보(46개 클래스의 분할 초평면을 복원하기에 충분한 정보)를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문입니다. 이 네트워크는 필요한 정보 대부분을 4차원 표현 안에 구겨 넣었지만 전부는 넣지 못했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 실험\n",
    "\n",
    "* 더 크거나 작은 층을 사용해 보세요: 32개 유닛, 128개 유닛 등\n",
    "* 여기에서 두 개의 은닉층을 사용했습니다. 한 개의 은닉층이나 세 개의 은닉층을 사용해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "다음은 이 예제에서 배운 것들입니다.\n",
    "\n",
    "* N개의 클래스로 데이터 포인트를 분류하려면 네트워크의 마지막 `Dense` 층의 크기는 N이어야 합니다.\n",
    "* 단일 레이블, 다중 분류 문제에서는 N개의 클래스에 대한 확률 분포를 출력하기 위해 `softmax` 활성화 함수를 사용해야 합니다.\n",
    "* 이런 문제에는 항상 범주형 크로스엔트로피를 사용해야 합니다. 이 함수는 모델이 출력한 확률 분포와 타깃 분포 사이의 거리를 최소화합니다.\n",
    "* 다중 분류에서 레이블을 다루는 두 가지 방법이 있습니다.\n",
    "    * 레이블을 범주형 인코딩(또는 원-핫 인코딩)으로 인코딩하고 `categorical_crossentropy` 손실 함수를 사용합니다.\n",
    "    * 레이블을 정수로 인코딩하고 `sparse_categorical_crossentropy` 손실 함수를 사용합니다.\n",
    "### * 많은 수의 범주를 분류할 때 중간층의 크기가 너무 작아 네트워크에 정보의 병목이 생기지 않도록 해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###LSTM으로 로이터 뉴스 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습에서는 등장 빈도 순서가 가장 많은 상위 1 ~ 1,000번째인 단어들만 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=1000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련용 뉴스 기사 데이터과 테스트용 뉴스 기사 데이터에 있는 각각의 뉴스의 길이는 서로 다릅니다. 즉, 각 기사는 단어의 수가 제각각입니다. 모델의 입력으로 사용하고자 모든 뉴스 기사의 길이를 동일하게 맞춥니다. pad_sequences()를 사용하여 maxlen의 값으로 100을 줬는데, 이는 모든 뉴스 기사의 길이. 즉, 단어 수를 100으로 일치시킨다는 뜻입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "X_train = pad_sequences(X_train, maxlen=max_len) # 훈련용 뉴스 기사 패딩\n",
    "X_test = pad_sequences(X_test, maxlen=max_len) # 테스트용 뉴스 기사 패딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스 기사에는 분명히 단어의 수가 100개가 넘는 경우도 있을 것이고, 100개가 안 되는 경우도 있을 것입니다. 그렇기 때문에 단어의 개수가 100개보다 많으면 100개만 선택하고 나머지는 제거하며, 100개보다 부족한 경우에는 부족한 부분이 0으로 패딩됩니다.\n",
    "\n",
    "이제 훈련용, 테스트용 뉴스 기사 데이터의 레이블에 원-핫 인코딩을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train) # 훈련용 뉴스 기사 레이블의 원-핫 인코딩\n",
    "y_test = to_categorical(y_test) # 테스트용 뉴스 기사 레이블의 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 Embedding()을 사용하여 임베딩 층(embedding layer)을 만들어야 하는데, Embedding()은 최소 두 개의 인자를 받습니다. 첫번째 인자는 단어 집합의 크기이며, 두번째 인자는 임베딩 벡터의 차원입니다. 결과적으로 위 코드에서 Embedding()은 120의 차원을 가지는 임베딩 벡터를 1,000개 생성하는 역할을 합니다. 그 후에 샘플들을 LSTM에다가 넣습니다. LSTM의 인자는 메모리 셀의 은닉 상태의 크기(hidden_size)입니다.\n",
    "\n",
    "46개의 카테고리를 분류해야하므로, 출력층에서는 46개의 뉴런을 사용합니다. 또한 출력층의 활성화 함수로 소프트맥스 함수를 사용합니다. 소프트맥스 함수는 각 입력에 대해서 46개의 확률 분포를 만들어냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://wikidocs.net/33520\n",
    "### https://heung-bae-lee.github.io/2020/01/16/NLP_01/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(1000, 120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(LSTM(120))\n",
    "model.add(Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터 손실(val_loss)이 증가하면, 과적합 징후므로 검증 데이터 손실이 4회 증가하면 학습을 조기 종료(Early Stopping)합니다. 또한, ModelCheckpoint를 사용하여 검증 데이터의 정확도(val_acc)가 이전보다 좋아질 경우에만 모델을 저장합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 컴파일합니다. 이 경우 다중 클래스 분류(Multi-Class Classification) 문제이므로 손실 함수로는 categorical_crossentropy를 사용합니다. categorical_crossentropy는 모델의 예측값과 실제값에 대해서 두 확률 분포 사이의 거리를 최소화하도록 훈련합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 학습합니다. validation_data로 X_test와 y_test를 사용합니다. val_loss가 줄어들다가 증가하는 상황이 오면 과적합(overfitting)으로 판단하기 위함입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.6222 - acc: 0.3554\n",
      "Epoch 00001: val_acc improved from -inf to 0.46661, saving model to best_model.h5\n",
      "71/71 [==============================] - 23s 327ms/step - loss: 2.6222 - acc: 0.3554 - val_loss: 2.3170 - val_acc: 0.4666\n",
      "Epoch 2/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.3609 - acc: 0.3700\n",
      "Epoch 00002: val_acc did not improve from 0.46661\n",
      "71/71 [==============================] - 22s 303ms/step - loss: 2.3609 - acc: 0.3700 - val_loss: 2.2416 - val_acc: 0.4492\n",
      "Epoch 3/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 2.0706 - acc: 0.4864\n",
      "Epoch 00003: val_acc improved from 0.46661 to 0.50801, saving model to best_model.h5\n",
      "71/71 [==============================] - 28s 399ms/step - loss: 2.0706 - acc: 0.4864 - val_loss: 2.0212 - val_acc: 0.5080\n",
      "Epoch 4/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.9647 - acc: 0.5092\n",
      "Epoch 00004: val_acc improved from 0.50801 to 0.51558, saving model to best_model.h5\n",
      "71/71 [==============================] - 23s 321ms/step - loss: 1.9647 - acc: 0.5092 - val_loss: 2.0515 - val_acc: 0.5156\n",
      "Epoch 5/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.8941 - acc: 0.5080\n",
      "Epoch 00005: val_acc improved from 0.51558 to 0.54675, saving model to best_model.h5\n",
      "71/71 [==============================] - 27s 379ms/step - loss: 1.8941 - acc: 0.5080 - val_loss: 1.7735 - val_acc: 0.5467\n",
      "Epoch 6/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.7259 - acc: 0.5544\n",
      "Epoch 00006: val_acc did not improve from 0.54675\n",
      "71/71 [==============================] - 25s 348ms/step - loss: 1.7259 - acc: 0.5544 - val_loss: 2.2141 - val_acc: 0.5174\n",
      "Epoch 7/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.7976 - acc: 0.5579\n",
      "Epoch 00007: val_acc improved from 0.54675 to 0.57391, saving model to best_model.h5\n",
      "71/71 [==============================] - 28s 401ms/step - loss: 1.7976 - acc: 0.5579 - val_loss: 1.7246 - val_acc: 0.5739\n",
      "Epoch 8/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.6137 - acc: 0.5834\n",
      "Epoch 00008: val_acc did not improve from 0.57391\n",
      "71/71 [==============================] - 27s 387ms/step - loss: 1.6137 - acc: 0.5834 - val_loss: 1.6452 - val_acc: 0.5708\n",
      "Epoch 9/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.5422 - acc: 0.5935\n",
      "Epoch 00009: val_acc improved from 0.57391 to 0.58593, saving model to best_model.h5\n",
      "71/71 [==============================] - 28s 388ms/step - loss: 1.5422 - acc: 0.5935 - val_loss: 1.6157 - val_acc: 0.5859\n",
      "Epoch 10/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.5116 - acc: 0.5993\n",
      "Epoch 00010: val_acc improved from 0.58593 to 0.59216, saving model to best_model.h5\n",
      "71/71 [==============================] - 24s 336ms/step - loss: 1.5116 - acc: 0.5993 - val_loss: 1.5763 - val_acc: 0.5922\n",
      "Epoch 11/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.4471 - acc: 0.6201\n",
      "Epoch 00011: val_acc improved from 0.59216 to 0.60374, saving model to best_model.h5\n",
      "71/71 [==============================] - 23s 323ms/step - loss: 1.4471 - acc: 0.6201 - val_loss: 1.5223 - val_acc: 0.6037\n",
      "Epoch 12/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.3705 - acc: 0.6414\n",
      "Epoch 00012: val_acc did not improve from 0.60374\n",
      "71/71 [==============================] - 25s 349ms/step - loss: 1.3705 - acc: 0.6414 - val_loss: 1.5313 - val_acc: 0.5975\n",
      "Epoch 13/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.3068 - acc: 0.6598\n",
      "Epoch 00013: val_acc improved from 0.60374 to 0.64826, saving model to best_model.h5\n",
      "71/71 [==============================] - 22s 315ms/step - loss: 1.3068 - acc: 0.6598 - val_loss: 1.3814 - val_acc: 0.6483\n",
      "Epoch 14/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.1934 - acc: 0.6958\n",
      "Epoch 00014: val_acc improved from 0.64826 to 0.67053, saving model to best_model.h5\n",
      "71/71 [==============================] - 25s 351ms/step - loss: 1.1934 - acc: 0.6958 - val_loss: 1.3349 - val_acc: 0.6705\n",
      "Epoch 15/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.1276 - acc: 0.7172\n",
      "Epoch 00015: val_acc improved from 0.67053 to 0.68077, saving model to best_model.h5\n",
      "71/71 [==============================] - 24s 344ms/step - loss: 1.1276 - acc: 0.7172 - val_loss: 1.2754 - val_acc: 0.6808\n",
      "Epoch 16/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.0637 - acc: 0.7308\n",
      "Epoch 00016: val_acc improved from 0.68077 to 0.69056, saving model to best_model.h5\n",
      "71/71 [==============================] - 27s 387ms/step - loss: 1.0637 - acc: 0.7308 - val_loss: 1.2503 - val_acc: 0.6906\n",
      "Epoch 17/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.0282 - acc: 0.7400\n",
      "Epoch 00017: val_acc improved from 0.69056 to 0.70703, saving model to best_model.h5\n",
      "71/71 [==============================] - 19s 270ms/step - loss: 1.0282 - acc: 0.7400 - val_loss: 1.1970 - val_acc: 0.7070\n",
      "Epoch 18/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.9782 - acc: 0.7533\n",
      "Epoch 00018: val_acc did not improve from 0.70703\n",
      "71/71 [==============================] - 19s 270ms/step - loss: 0.9782 - acc: 0.7533 - val_loss: 1.2285 - val_acc: 0.6950\n",
      "Epoch 19/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.9318 - acc: 0.7640\n",
      "Epoch 00019: val_acc improved from 0.70703 to 0.71104, saving model to best_model.h5\n",
      "71/71 [==============================] - 20s 284ms/step - loss: 0.9318 - acc: 0.7640 - val_loss: 1.2030 - val_acc: 0.7110\n",
      "Epoch 20/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.8961 - acc: 0.7737\n",
      "Epoch 00020: val_acc improved from 0.71104 to 0.71238, saving model to best_model.h5\n",
      "71/71 [==============================] - 20s 284ms/step - loss: 0.8961 - acc: 0.7737 - val_loss: 1.1688 - val_acc: 0.7124\n",
      "Epoch 21/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.8557 - acc: 0.7852\n",
      "Epoch 00021: val_acc improved from 0.71238 to 0.72084, saving model to best_model.h5\n",
      "71/71 [==============================] - 21s 292ms/step - loss: 0.8557 - acc: 0.7852 - val_loss: 1.1661 - val_acc: 0.7208\n",
      "Epoch 22/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.8261 - acc: 0.7910\n",
      "Epoch 00022: val_acc did not improve from 0.72084\n",
      "71/71 [==============================] - 20s 286ms/step - loss: 0.8261 - acc: 0.7910 - val_loss: 1.1615 - val_acc: 0.7155\n",
      "Epoch 23/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.7823 - acc: 0.8014\n",
      "Epoch 00023: val_acc improved from 0.72084 to 0.72306, saving model to best_model.h5\n",
      "71/71 [==============================] - 20s 280ms/step - loss: 0.7823 - acc: 0.8014 - val_loss: 1.1694 - val_acc: 0.7231\n",
      "Epoch 24/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.7517 - acc: 0.8094\n",
      "Epoch 00024: val_acc improved from 0.72306 to 0.72529, saving model to best_model.h5\n",
      "71/71 [==============================] - 20s 283ms/step - loss: 0.7517 - acc: 0.8094 - val_loss: 1.1544 - val_acc: 0.7253\n",
      "Epoch 25/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.7367 - acc: 0.8164\n",
      "Epoch 00025: val_acc did not improve from 0.72529\n",
      "71/71 [==============================] - 20s 280ms/step - loss: 0.7367 - acc: 0.8164 - val_loss: 1.2304 - val_acc: 0.7115\n",
      "Epoch 26/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.7006 - acc: 0.8258\n",
      "Epoch 00026: val_acc did not improve from 0.72529\n",
      "71/71 [==============================] - 22s 307ms/step - loss: 0.7006 - acc: 0.8258 - val_loss: 1.1875 - val_acc: 0.7115\n",
      "Epoch 27/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.6709 - acc: 0.8314\n",
      "Epoch 00027: val_acc did not improve from 0.72529\n",
      "71/71 [==============================] - 21s 297ms/step - loss: 0.6709 - acc: 0.8314 - val_loss: 1.1763 - val_acc: 0.7208\n",
      "Epoch 28/30\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.6399 - acc: 0.8403\n",
      "Epoch 00028: val_acc did not improve from 0.72529\n",
      "71/71 [==============================] - 21s 297ms/step - loss: 0.6399 - acc: 0.8403 - val_loss: 1.1960 - val_acc: 0.7110\n",
      "Epoch 00028: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=30, callbacks=[es, mc], validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 3s 49ms/step - loss: 1.1544 - acc: 0.7253\n",
      "\n",
      " 테스트 정확도: 0.7253\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(history.history['acc']) + 1)\n",
    "plt.plot(epochs, history.history['loss'])\n",
    "plt.plot(epochs, history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
